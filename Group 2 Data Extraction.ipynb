{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "page = urlopen('https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/CounselingServices')\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "\n",
    "def rule1(url):# have no beforeSubHead,only accordion-group\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip() + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    head = soup2.h2.get_text()\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    content = allContent.find_all('div', attrs={'class': 'accordion-group'})\n",
    "    f.write('head' + '\\t' + head+'\\n')\n",
    "    for j in content:\n",
    "        subHead=j.a.get_text()\n",
    "        subContent=j.p.get_text()\n",
    "        f.write(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "        f.write('\\n')\n",
    "        #print(subHead)\n",
    "        #print(subContent)\n",
    "    return;\n",
    "\n",
    "def rule2(url):# have beforeSubHead and accordion-group\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip() + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    head = soup2.h1.get_text()\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    beforeHead=allContent.p.get_text()\n",
    "    print(beforeHead)\n",
    "    content = allContent.find_all('div', attrs={'class': 'accordion-group'})\n",
    "    f.write('head' + '\\t' + head+'\\n')\n",
    "    f.write('beforeHead' + '\\t' + beforeHead + '\\n')\n",
    "    for j in content:\n",
    "        subHead=j.a.get_text()\n",
    "        subContent=j.p.get_text()\n",
    "        #print(type(subContent))\n",
    "        f.write(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "        f.write('\\n')\n",
    "        #print(subHead)\n",
    "        #print(subContent.split(\".\"))\n",
    "        print(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "    return;\n",
    "\n",
    "def rule3(url):# have beforeSubHead, 2h2 and accordion-group\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip() + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    allHead = soup2.find_all('h2')\n",
    "\n",
    "    head1=allHead[0].get_text()\n",
    "    head2=allHead[1].get_text()\n",
    "\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    beforeHead=allContent.find_all('p',recursive=False)\n",
    "    resultBeforeHead=''\n",
    "    for i in beforeHead:\n",
    "        resultBeforeHead=resultBeforeHead+i.get_text()+' '\n",
    "\n",
    "    f.write(head1+'\\t' + resultBeforeHead+ '\\n')\n",
    "    f.write('head2'+'\\t'+head2+ '\\n')\n",
    "    print(head1+'\\t' + resultBeforeHead)\n",
    "    print('head'+'\\t'+head2)\n",
    "    content = allContent.find_all('div', attrs={'class': 'accordion-group'})\n",
    "\n",
    "    for j in content:\n",
    "        subHead=j.a.get_text()\n",
    "        subContent=j.p.get_text()\n",
    "        #print(type(subContent))\n",
    "        f.write(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "        f.write('\\n')\n",
    "\n",
    "        print(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "    return;\n",
    "\n",
    "def rule4(url):#https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/Self-HelpLibrary\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip() + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    head = soup2.h1.get_text()\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    subHead=allContent.h4.get_text()\n",
    "    print(subHead)\n",
    "    subContent=allContent.find_all('p')\n",
    "    resultSubContent = ''\n",
    "    for i in subContent:\n",
    "        resultSubContent = resultSubContent + i.get_text() + ' '\n",
    "\n",
    "    otherContent=allContent.ul.get_text().strip().replace('\\n','. ').replace('\\r','. ')\n",
    "    resultSubContent=resultSubContent+otherContent\n",
    "    print(resultSubContent)\n",
    "\n",
    "    f.write('head' + '\\t' + head+'\\n')\n",
    "    f.write(subHead + '\\t' + resultSubContent + '\\n')\n",
    "\n",
    "    return;\n",
    "\n",
    "def rule5(url):#https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/Parents\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip() + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    allHead = soup2.find_all('h3')\n",
    "\n",
    "    head1=allHead[0].get_text()\n",
    "    head2=allHead[1].get_text()\n",
    "\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    beforeHead=allContent.find_all('p',recursive=False)\n",
    "    content1=beforeHead[0].get_text()\n",
    "    content2=''\n",
    "    for i in beforeHead[1:]:\n",
    "        content2=content2+i.get_text().replace('\\n',' ').replace('\\r',' ')+'. '\n",
    "    print(content2)\n",
    "    f.write(head1+'\\t' + content1+ '\\n')\n",
    "    f.write(head2+'\\t'+content2+ '\\n')\n",
    "    print(head1+'\\t' + content1)\n",
    "    print(head2+'\\t'+content2)\n",
    "    head3=allContent.h2.get_text()\n",
    "    f.write('head'+'\\t'+head3+ '\\n')\n",
    "    content = allContent.find_all('div', attrs={'class': 'accordion-group'})\n",
    "\n",
    "    for j in content:\n",
    "        subHead=j.a.get_text()\n",
    "        subContent=j.p.get_text()\n",
    "        #print(type(subContent))\n",
    "        f.write(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "        f.write('\\n')\n",
    "\n",
    "        print(subHead+'\\t'+subContent.replace('\\n',' ').replace('\\r',' '))\n",
    "    return;\n",
    "\n",
    "\n",
    "def rule6(url):# get head and content\n",
    "    secondPage = urlopen(url)\n",
    "    soup2 = BeautifulSoup(secondPage, 'html.parser')\n",
    "    filePath = 'C:/' + soup2.title.get_text().strip().replace('/','') + '.txt'\n",
    "    f = open(filePath, 'w', encoding='utf8')\n",
    "    head = soup2.h1.get_text()\n",
    "    allContent = soup2.find('div', attrs={'class': 'span9'})\n",
    "    print(allContent.get_text().strip().replace('\\n',' ').replace('\\r',' '))\n",
    "    f.write(head + '\\t' + allContent.get_text().strip().replace('\\n',' ').replace('\\r',' ') + '\\n')\n",
    "    return;\n",
    "\n",
    "\n",
    "navList = soup.find('ul', attrs={'class':'nav nav-list'}).find_all('a')\n",
    "for i in navList[2:]:\n",
    "    filePath='C:/'+i.get_text().strip()+'.txt'\n",
    "    #f = open(filePath, 'w', encoding='utf8')\n",
    "    url='https://www.smu.edu'+i.attrs['href']\n",
    "    print(url)\n",
    "    if(url=='https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/CounselingServices'):\n",
    "        rule1(url)\n",
    "    elif(url=='https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/GroupCounseling'):\n",
    "        rule2(url)\n",
    "    elif (url == 'https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/PsychiatricServices'):\n",
    "        rule2(url)\n",
    "    elif (url == 'https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/Appointments'):\n",
    "        rule3(url)\n",
    "    elif (url == 'https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/Self-HelpLibrary'):\n",
    "        rule4(url)\n",
    "    elif (url == 'https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/Parents'):\n",
    "        rule5(url)\n",
    "    elif (url == 'https://www.smu.edu/StudentAffairs/HealthCenter/Counseling/AlcoholDrugServices'):\n",
    "        rule2(url)\n",
    "    else:\n",
    "        rule6(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
